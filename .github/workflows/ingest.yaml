name: ingest
on:
  schedule:
    - cron: "*/5 * * * *"
  workflow_dispatch: {}
concurrency: ingest
env:
  KAMU_VERSION: v0.91.0
  PINATA_API_URL: https://api.pinata.cloud/psa
  PINATA_GATEWAY: https://gateway.pinata.cloud
  PINATA_ACCESS_TOKEN: ${{ secrets.PINATA_ACCESS_TOKEN }}
  AWS_ROUTE53_HOSTED_ZONE_ID: Z25CPWZR4S9IHS
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_DEFAULT_REGION: us-west-2
  AWS_ROUTE53_TTL: 60
  # Required by dataset fetch steps
  ETH_NODE_PROVIDER_URL: ${{ secrets.INFURA_NODE_URL }}
  ALPHA_VANTAGE_API_KEY: ${{ secrets.ALPHA_VANTAGE_API_KEY }}
jobs:
  update:
    name: Update Dataset
    strategy:
      matrix:
        dataset_name:
          - com.coinpaprika.tickers.eth-usd
          - net.rocketpool.reth.mint-burn
          - co.alphavantage.tickers.daily.spy
        include:
          - dataset_name: com.coinpaprika.tickers.eth-usd
            ipns_id: k51qzi5uqu5dgxqmxnxblkbh0z56k4o7rpxani1u6s3z5u2oew1zerzbxhcs3j
            ipns_key_secret: COINPAPRIKA_TICKERS_ETH_USD_KEY
            dnslink_subdomain: com.coinpaprika.tickers.eth-usd.datasets.kamu.dev
          - dataset_name: net.rocketpool.reth.mint-burn
            ipns_id: k51qzi5uqu5dj6e8rprw175y8tqt55ipji4c1maqqtpxl11gpnpd3qb7luta6r
            ipns_key_secret: NET_ROCKETPOOL_RETH_MINT_BURN_KEY
            dnslink_subdomain: net.rocketpool.reth.mint-burn.datasets.kamu.dev
          - dataset_name: co.alphavantage.tickers.daily.spy
            ipns_id: k51qzi5uqu5djln0j1uan84f9btedeqfi9inj1exw8xj4dp9tpc2znbedkcazy
            ipns_key_secret: CO_ALPHAVANTAGE_TICKERS_DAILY_SPY_KEY
            dnslink_subdomain: co.alphavantage.tickers.daily.spy.datasets.kamu.dev
    runs-on: ubuntu-latest
    steps:
      - uses: ibnesayeed/setup-ipfs@master
        with:
          ipfs_version: ^0.12
          run_daemon: true

      - name: Install kamu
        shell: bash
        run: |
          wget -q "https://github.com/kamu-data/kamu-cli/releases/download/$KAMU_VERSION/kamu-cli-x86_64-unknown-linux-gnu.tar.gz"
          tar -xf kamu-cli-x86_64-unknown-linux-gnu.tar.gz
          chmod +x kamu-cli-x86_64-unknown-linux-gnu/kamu
          echo "$PWD/kamu-cli-x86_64-unknown-linux-gnu" >> $GITHUB_PATH

      - name: Print versions
        shell: bash
        run: |
          echo "IPFS version:"
          ipfs version

          echo "Podman version:"
          podman version

          echo "AWS CLI version:"
          aws --version

          echo "Kamu version:"
          kamu --version

      # TODO: IPFS daemon often times out when searching for a CID :(
      # we point kamu to Pinata's own IPFS gateway to increase chances of resolving it fast
      - name: Configure
        shell: bash
        env:
          IPNS_KEY: ${{ secrets[matrix.ipns_key_secret] }}
        run: |
          # Add IPNS key
          echo $IPNS_KEY | base64 -d > ipns_key
          ipfs key import ${{ matrix.dataset_name }} ipns_key
          rm ipns_key

          # Add pinning service
          ipfs pin remote service add svc "$PINATA_API_URL" "$PINATA_ACCESS_TOKEN"

          # Create workspace and point kamu to Pinata IPFS gateway
          kamu init
          kamu config set protocol.ipfs.httpGateway "$PINATA_GATEWAY"

      # TODO: We use DNSLink instead of IPNS due to IPNS's current usability issues like:
      # - frequent loss of writes
      # - lack of read-after-write consistency
      # - abysmal resolution times and frequent timeouts

      # - name: Pull dataset
      #   shell: bash
      #   run: |
      #     ipfs_cid=$(ipfs name resolve "/ipns/$IPNS_ID" | grep -oE "[^/]+$")
      #     echo "Current IPFS CID: $ipfs_cid"

      - name: Download dataset
        shell: bash
        run: |
          ipfs_cid=$( \
            aws route53 list-resource-record-sets \
            --hosted-zone-id $AWS_ROUTE53_HOSTED_ZONE_ID \
            | jq -r ".ResourceRecordSets[] | select(.Name == \"_dnslink.${{ matrix.dnslink_subdomain }}.\") | .ResourceRecords[0].Value" \
            | grep -oE '[^/]+"$' \
            | grep -oE '^[^"]+'
          )

          echo "Current IPFS CID in DNSLink: $ipfs_cid"

          kamu -v pull "ipfs://$ipfs_cid" --as ${{ matrix.dataset_name }} --no-alias
          kamu list --output-format table -w

      - name: Ingest new data
        shell: bash
        run: |
          kamu -v pull ${{ matrix.dataset_name }}
          kamu list --output-format table -w

      - name: Publish updated dataset
        shell: bash
        run: |
          # Add dataset to IPFS and publish to IPNS
          kamu -v push ${{ matrix.dataset_name }} --to "ipns://${{ matrix.ipns_id }}"

          # Get new CID
          ipfs_cid=$(ipfs name resolve "/ipns/${{ matrix.ipns_id }}" | grep -oE "[^/]+$")
          echo "New IPFS CID: $ipfs_cid"

          # Pin new CID to replicate data to the pinning service
          # TODO: `ipfs pin remote add` errors out on duplicate pin instead of ignoring them, with a non-distinguishable error code
          # so we have to ignore all errors now. It would be better to compare CIDs and add only if they changed.
          ipfs pin remote add --service svc --name ${{ matrix.dataset_name }} -- "/ipfs/$ipfs_cid" || true

          # Update DNSLink entry
          echo "{
              \"Comment\": \"GHAction update of DNSLink record\",
              \"Changes\": [
                  {
                      \"Action\": \"UPSERT\",
                      \"ResourceRecordSet\": {
                          \"Name\": \"_dnslink.${{ matrix.dnslink_subdomain }}.\",
                          \"Type\": \"TXT\",
                          \"TTL\": $AWS_ROUTE53_TTL,
                          \"ResourceRecords\": [{
                              \"Value\": \"\\\"dnslink=/ipfs/$ipfs_cid\\\"\"
                          }]
                      }
                  }
              ]
          }" > dns-upsert.json
          echo "Updating DNSLink entry with: $(cat dns-upsert.json)"
          aws route53 change-resource-record-sets --hosted-zone-id $AWS_ROUTE53_HOSTED_ZONE_ID --change-batch file://dns-upsert.json

      # - name: Ingest & push loop
      #   shell: bash
      #   run: |
      #     stop_time=$((SECONDS + LOOP_TOTAL_SEC))
      #     while [ $SECONDS -lt $stop_time ]; do
      #       # Chill
      #       echo "Sleeping for $LOOP_SLEEP_SEC seconds..."
      #       sleep $LOOP_SLEEP_SEC
      #     done
